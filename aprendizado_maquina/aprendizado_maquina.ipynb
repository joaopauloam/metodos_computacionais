{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aprendizado de Máquina\n",
    "\n",
    "+ Aprendizado de Máquina é uma área de IA cujo objetivo é o desenvolvimento de técnicas computacionais sobre o aprendizado bem como a construção de sistemas capazes de adquirir conhecimento de forma automática\n",
    "+ Um sistema de aprendizado é um programa de computador que toma decisões baseado em experiências acumuladas através da solução bem sucedida de problemas anteriores\n",
    "+ Nas últimas décadas o aprendizado de máquina tornou-se um dos pilares em tecnologia da informação\n",
    "+ Embora hoje seja parte central do nosso cotidiano, seus conceitos não são claros para a maioria da pessoas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemplos\n",
    "\n",
    "+ Ranqueamento de páginas web\n",
    "    + Em uma busca na web o motor de busca retorna os resultados mais relevantes\n",
    "    + Como classificar a relevância das páginas encontradas?\n",
    "![alt_text](ranqueamento.png)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemplos\n",
    "\n",
    "+ Filtro colaborativo\n",
    "    + Livrarias como a Amazon ou serviços de streaming como o Netflix usam essa informação para sugerir livros, filmes ou séries\n",
    "    + Essa sugestão pode ser \"aprendida\" com base em compras passadas do próprio usuário ou de decisões tomadas por usuários parecidos\n",
    "![alt_text](filtro_colaborativo.png)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemplos\n",
    "\n",
    "+ Tradução automática\n",
    "    + Documentos traduzidos podem servir de exemplo para a aprendizagem de um tradutor automático\n",
    "+ Reconhecimento de discurso\n",
    "    + Traduzir um áudio em texto\n",
    "    + Traduzir um texto escrito a mão em um texto digitado    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemplos\n",
    "\n",
    "+ Classificador\n",
    "    + Dada a foto de uma pessoa um sistema de segurança pode tentar identificar em sua base de dados quem é aquela pessoa\n",
    "    + Ou ainda, o sistema pode verificar se aquela pessoa é quem realmente diz ser\n",
    "![alt_text](verificacao.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[![O dilema das fritas enroladas](video.png)](https://www.ted.com/talks/jennifer_golbeck_the_curly_fry_conundrum_why_social_media_likes_say_more_than_you_might_think?language=pt-br#t-1752 \"O dilema das fritas enroladas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classificação\n",
    "\n",
    "+ Problema comum em aprendizado de máquina\n",
    "+ Exemplo: filtro de spam\n",
    "    + Depende do usuário a classificação de um e-mail em spam ou não\n",
    "+ Exemplo: Diagnosticar câncer em um paciente com base em dados histológicos\n",
    "+ Estes são exemplos de classificação binária\n",
    "![alt_text](classificacao_binaria.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dados\n",
    "\n",
    "+ É útil caracterizar os problemas de aprendizagem de acordo com o tipo de dados que eles trabalham\n",
    "+ Isso possibilita que quando novos desfios são encontrados com tipos de dados similares, técnicas similares possam ser utilizadas\n",
    "+ Por exemplo, processamento de linguagem natural e bioinformática usam técnicas bastante similares para tratarem as strings enconytradas nos textos de linguagem natural e nas sequências de DNA\n",
    "+ Os **vetores** constituem a entidade básica para codificar os dados trabalhados em aprendizado de máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dados\n",
    "\n",
    "+ Por exemplo, para uma companhia de seguro de vida seria interessante obter um vetor de variáveis  (pressão sanguínea, batimentos cardíacos, altura, peso, nível de colesterol, fumante, gênero) para inferir a expectativa de vida de um cliente em potencial.\n",
    "+ Um engenheiro pode querer descobrir dependências entre pares (voltagem, corrente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dados\n",
    "\n",
    "+ Referência: http://dcm.ffclrp.usp.br/~augusto/teaching/ami/AM-I-Conceitos-Definicoes.pdf\n",
    "+ De maneira geral, dados pares (x,f(x)), inferir f.\n",
    "![alt_text](dados.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dados\n",
    "\n",
    "+ Dada uma amostra finita, normalmente é impossível determinar a verdadeira função f.\n",
    "+ Abordagem: Encontre uma hipótese ( modelo ) nos exemplos de treinamento e assuma que a hipótese se repita para exemplos futuros também"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exemplos\n",
    "\n",
    "+ [Chemistry world](https://www.chemistryworld.com/1616.tag)\n",
    "    + [Ligand selector steers C–N cross-couplings down most sustainable path](Ligand.pdf)\n",
    "    + [Neural network folds proteins a million times faster than its competitors](Neural.pdf)\n",
    "    + [Algorithm accurately predicts mechanical properties of existing and theoretical MOFs](MOF.pdf)\n",
    "    + [Lithium–ion battery book written by machine learning algorithm](Lithium.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dados\n",
    "\n",
    "![alt_text](dados2.png)\n",
    "+ $f: X_1 \\times X_2 \\times X_3 \\times X_4 \\rightarrow Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problemas\n",
    "\n",
    "+ Classificação binária\n",
    "+ Classificação multiclasse\n",
    "+ Estimativa estruturada\n",
    "+ Regressão\n",
    "+ Detecção de novidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hierarquia do aprendizado\n",
    "![alt_text](hierarquia_aprendizado.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Como funciona o aprendizado de máquina\n",
    "![alt_text](aprendizado.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Como funciona o aprendizado de máquina\n",
    "![alt_text](aprendizado2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Como funciona o aprendizado de máquina\n",
    "![alt_text](aprendizado3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Como funciona o aprendizado de máquina\n",
    "![alt_text](aprendizado4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## AS X AnS\n",
    "+ Aprendizado Supervisionado\n",
    "    + Compreender o relacionamento entre os atributos e a classe\n",
    "    + Predizer a classe de novos exemplos o melhor possível\n",
    "+ Aprendizado Não Supervisionado\n",
    "    + Encontrar representações úteis dos exemplos, tais como:\n",
    "        + Encontrar agrupamentos (clusters)\n",
    "        + Redução da dimensão\n",
    "        + Encontrar as causas ou as fontes ocultas dos exemplos\n",
    "        + Modelar a densidade dos exemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemplo, Atributo e Classe\n",
    "+ Exemplo\n",
    "    + Exemplo, caso, registro ou instância\n",
    "    + É um conjunto fixo de atributos\n",
    "    + Um exemplo descreve o objeto de interesse, tal como um paciente, exemplos médicos sobre uma determinada doença ou histórico de clientes de uma dada companhia\n",
    "+ Atributo\n",
    "    + Atributo, campo ou característica (feature)\n",
    "    + Uma única característica de um exemplo\n",
    "+ Classe\n",
    "    + Atributo especial que descreve o fenômeno de interesse (somente no Aprendizado Supervisionado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemplo, Atributo e Classe\n",
    "![alt_text](exemplos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conjuntos de Exemplos\n",
    "\n",
    "+ Em geral, um conjunto de exemplos é dividido em dois subconjuntos disjuntos:\n",
    "    + conjunto de treinamento que é usado para o aprendizado do conceito e o\n",
    "    + conjunto de teste que é usado para medir o grau de efetividade do conceito aprendido\n",
    "+     Os subconjuntos são disjuntos para assegurar que as medidas obtidas utilizando o conjunto de teste sejam de um conjunto diferente do usado para realizar o aprendizado, tornando a medida estatisticamente válida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Erro aparente\n",
    "![alt_text](erro1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Erro verdadeiro\n",
    "![alt_text](erro2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preparação de dados\n",
    "\n",
    "+ Fase que antecede o processo de aprendizagem, para facilitar ou melhorar o processo.\n",
    "+ Exemplos:\n",
    "    + remover exemplos incorretos\n",
    "    + transformar o formato dos exemplos para que possam ser usados com um determinado indutor\n",
    "    + selecionar um subconjunto de atributos relevantes (FSS – Feature Subset Selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sobreajuste (overfitting)\n",
    "\n",
    "+ A hipótese extraída a partir dos exemplos é muito específica para o conjunto de treinamento\n",
    "+ A hipótese apresenta um bom desempenho para o conjunto de treinamento, mas um desempenho ruim para os casos fora desse conjunto\n",
    "![alt_text](overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Subajuste (underfitting)\n",
    "\n",
    "+ A hipótese induzida apresenta um desempenho ruim tanto no conjunto de treinamento como no de teste\n",
    "![alt_text](overfitting_underfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dado, Informação, Conhecimento\n",
    "\n",
    "+ Dado: é a estrutura fundamental sobre a qual um sistema de informação é construído\n",
    "+ Informação: a transformação de dados em informação é freqüentemente realizada através da apresentação dos dados em uma forma compreensível ao usuário\n",
    "+ Conhecimento:\n",
    "    + Fornece a capacidade de resolver problemas, inovar e aprender baseado em experiências prévias\n",
    "    + Uma combinação de instintos, idéias, regras e procedimentos que guiam as ações e decisões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estrutura\n",
    "![alt_text](estrutura.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importante\n",
    "\n",
    "+ Dado não é Informação\n",
    "+ Informação não é Conhecimento\n",
    "+ Conhecimento não é Inteligência\n",
    "+ Inteligência não é Sabedoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quimiometria\n",
    "\n",
    "+ Talvez a principal aplicação de aprendizado de máquina em química se dê no campo de pesquisa conhecido como **quimiometria**.\n",
    "+ Algumas definições de quimiometria:\n",
    "    + A quimiometria é a aplicação de ferramentas matemáticas e estatísticas à química (Bruce Kowalski).\n",
    "    + Quimiometria é a aplicação de estatística  à análise de dados químicos (de química orgânica, analítica ou de química medicinal) e o planejamento de experimentos químicos e simulações (IUPAC).\n",
    "    + Quimiometria é a disciplina química que usa métodos matemáticos e estatísticos para:\n",
    "        + planejar ou otimizar procedimentos experimentais; e\n",
    "        + extrair o máximo da informação química relevante, através da análise dos dados (Bruce Kowalski).\n",
    "    + Quimiometria é o que os quimiometristas fazem (Quimiometrista anônimo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quimiometria\n",
    "\n",
    "+ Na parte de análise de dados os principais métodos usados em quimiometria são:\n",
    "    + Análise exploratória (aprendizado não supervisionado)\n",
    "        + HCA\n",
    "        + PCA\n",
    "    + Métodos de regressão (aprendizado supervisionado)\n",
    "        + MLR\n",
    "        + PCR\n",
    "        + PLS\n",
    "    + Métodos de classificação (aprendizado supervisionado)\n",
    "        + KNN\n",
    "        + SIMCA\n",
    "        + PLS-DA\n",
    "        + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scikit-learn\n",
    "https://scikit-learn.org/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Análise de Agrupamentos por métodos hierárquicos (HCA)\n",
    "\n",
    "+ A nálise de agrupamentos por métodos hierárquicos (HCA, do inglês *hierarquical cluster analysis*), teve origem na taxonomia numérica\n",
    "+ É um método de aprendizado não-supervisionado de reconhecimento de padrões, adequado para descobrir \"padrões naturais\" de comportamento entre amostras\n",
    "+ HCA é útil para reduzir a dimensionalidade dos dados de grande porte, por exemplo, permitindo que dezenas de milhares de genes possam ser representados por poucos grupos de genes de comportamento semelhante\n",
    "+ Outro exemplo uso do HCA é na detecção de amostras com comportamento anômalo em um conjunto de dados\n",
    "+ Outro exemplo na busca por estruturas cristalográficas similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Análise de Agrupamentos por métodos hierárquicos (HCA)\n",
    "\n",
    "+ O HCA é uma técnica interessante porque permite a visualização de dados multidimensionais por meio de um esquema bidimensional\n",
    "+ Os resultados são apresentados na forma de uma árvore hierárquica também conhecida como **dendrograma**\n",
    "+ O HCA é uma técnica algomerativa, na qual cada objeto é considerado um grupo unitário. A seguir eles vão sendo agrupados sistematicamente por ordem de similaridade, em um processo iterativo, até que todos eles formem um único grupo\n",
    "+ É muito razoável assumir que amostras próximas entre si no espaço multidimensional, $R^J$, sejam semelhantes em relação às variáveis selecionadas\n",
    "+ Isso quer dizer que uma maneira de determinar o quanto um objeto é semelhante a outro é por meio do cálculo da distância entre eles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Análise de Agrupamentos por métodos hierárquicos (HCA)\n",
    "\n",
    "+ Essa distância pode ser:\n",
    "    + Euclideana\n",
    "        $d_{AB}^M = [(\\mathbf{x_A}-\\mathbf{x_B})^T (\\mathbf{x_A}-\\mathbf{x_B})]^{1/2} = \\|\\mathbf{x_A}-\\mathbf{x_B} \\|_2$\n",
    "    + Manhattan\n",
    "        $d_{AB}^M = \\|\\mathbf{x_A}-\\mathbf{x_B} \\|_1 = \\sum_{j=1}^{J}|x_{aj}-x_{bj}|$\n",
    "    + Mahalanobis\n",
    "        $d_{AB}^M = [(\\mathbf{x_A}-\\mathbf{x_B})^T \\mathbf{Var}^{-1}(\\mathbf{x_A}-\\mathbf{x_B})]^{1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"liquens.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_numbers = df.iloc[2:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_numbers.index = range(1,len(df_numbers)+1)\n",
    "df_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for i in range (df_numbers.shape[0]):\n",
    "    for j in range (df_numbers.shape[1]):\n",
    "        if df_numbers.iloc[i,j] == \"<LD\":\n",
    "            df_numbers.iloc[i,j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(df_numbers.index[i],df.iloc[2:,1][i]) for i in range(len(df_numbers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(df.iloc[2:,1][i]) for i in range(len(df_numbers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "Z = linkage(df_numbers, 'ward')\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "dn = dendrogram(Z,orientation=\"right\",labels=[(df_numbers.index[i],df.iloc[2+i,1],df.iloc[2+i,0]) for i in range(len(df_numbers))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Análise de componentes principais (PCA)\n",
    "\n",
    "+ A análise de componentes principais (PCA, do inglês *principal component analysis*) é um método utilizado para projetar os dados multivariados em um espaço de menor dimensão reduzindo, assim, a dimensionalidade do espaço original do conjunto de dados, sem que a relação entre as amostras seja afetada\n",
    "+ Utilizando essa metodologia é possível descobrir, visualizar e interpretar as diferenças existentes entre as variáveis e examinar as relações que podem existir entre as amostras\n",
    "+ Esa análise também nos permite detectar amostras que apresentam um comportamento distinto (atípico)\n",
    "+ Os metodos de projeção são importantes na área de meteorologia para o tratamento de imagens de satélite\n",
    "+ Em química são importantes para o tratamento de dados de espectroscopia e cromatografia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Análise de componentes principais (PCA)\n",
    "\n",
    "+ Em PCA é possível fazer uma \"compressão\" dos dados por meio da criação de um novo conjunto de variáveis que são combinações lineares das variáveis originais\n",
    "+ Essas novas variáveis são as componentes principais, PC, também conhecidas por fatores ou autovetores\n",
    "+ Um propriedades importante das PCs é que são não correlacionadas e ortogonais entre si\n",
    "+ Outra propriedade importante é que a primeira PC (PC1) é definida pela direção que descreve a máxima variância dos dados originais\n",
    "+ PC2 tem a direção de máxima variância dos dados no subespaço ortogonal à PC1 e assim sucessivamente\n",
    "+ O número de componentes principais, *A*, que é necessário para descrever adequadamente o sistema em estudo, é chamado de dimensão intrínseca, pseudoposto ou posto químico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Análise de componentes principais (PCA)\n",
    "\n",
    "+ Matematicamente PCA equivale a decompor a matriz  **X**(*I* X *J*) em duas matrizes, uma de escores **T** e uma matriz ortonormal de pesos (*loadings*) **L**, de tal maneira que\n",
    "\n",
    "$\\mathbf{X} = \\mathbf{T}\\mathbf{L}^T$\n",
    "\n",
    "+ em que os escores expressam as relações entre as amostras, enquanto que os pesos indicam as relações entre as variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "df = pd.read_excel(\"liquens.xls\")\n",
    "df_numbers = df.iloc[2:,2:]\n",
    "df_numbers = df_numbers.replace(\"<LD\",0)\n",
    "Xa = StandardScaler().fit_transform(df_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=6)\n",
    "pca.fit(Xa)  \n",
    "print(pca.explained_variance_ratio_)  \n",
    "print(pca.singular_values_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "L= pca.components_.T\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "T = pca.transform(Xa)\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import LabelSet, Label, ColumnDataSource\n",
    "import numpy as np\n",
    "source = ColumnDataSource(data=dict(PC1=T[:,0],\n",
    "                                    PC2=T[:,1],\n",
    "                                    names=df_numbers.index))\n",
    "\n",
    "output_notebook()\n",
    "p = figure(title=\"Gráfico de escores\", x_axis_label='PC1', y_axis_label='PC2')\n",
    "p.scatter('PC1','PC2',color='blue',size=6, source=source)\n",
    "labels = LabelSet(x='PC1', y='PC2', text='names', level='glyph',\n",
    "              x_offset=5, y_offset=5, source=source, render_mode='canvas')    \n",
    "p.add_layout(labels)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "source = ColumnDataSource(data=dict(PC1=L[:,0],\n",
    "                                    PC2=L[:,1],\n",
    "                                    names=df_numbers.columns))\n",
    "\n",
    "output_notebook()\n",
    "p = figure(title=\"Gráfico de pesos(loadings)\", x_axis_label='PC1', y_axis_label='PC2')\n",
    "p.scatter('PC1','PC2',color='blue',size=6, source=source)\n",
    "labels = LabelSet(x='PC1', y='PC2', text='names', level='glyph',\n",
    "              x_offset=5, y_offset=5, source=source, render_mode='canvas')    \n",
    "p.add_layout(labels)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Novo conjunto de dados\n",
    "flav = pd.read_csv(\"../flavonoides2.csv\",sep='\\t',index_col=0)\n",
    "flav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X = flav.iloc[:,:-1]\n",
    "y = flav.iloc[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## PCA\n",
    "\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import LabelSet, Label, ColumnDataSource\n",
    "import numpy as np\n",
    "pca = PCA(n_components=6)\n",
    "Xa = StandardScaler().fit_transform(X)\n",
    "pca.fit(Xa)\n",
    "#T = Xa.dot(pca.components_.T)\n",
    "T = pca.fit_transform(Xa)\n",
    "source = ColumnDataSource(data=dict(PC1=T[:,0],\n",
    "                                    PC2=T[:,1],\n",
    "                                    names=flav.index))\n",
    "\n",
    "output_notebook()\n",
    "p = figure(title=\"Gráfico de escores\", x_axis_label='PC1', y_axis_label='PC2')\n",
    "p.scatter('PC1','PC2',color='blue',size=6, source=source)\n",
    "labels = LabelSet(x='PC1', y='PC2', text='names', level='glyph',\n",
    "              x_offset=5, y_offset=5, source=source, render_mode='canvas')    \n",
    "p.add_layout(labels)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "L = pca.components_.T\n",
    "source = ColumnDataSource(data=dict(PC1=L[:,0],\n",
    "                                    PC2=L[:,1],\n",
    "                                    names=flav.columns[:-1]))\n",
    "\n",
    "output_notebook()\n",
    "p = figure(title=\"Gráfico de pesos(loadings)\", x_axis_label='PC1', y_axis_label='PC2')\n",
    "# for i in range(np.shape(T)[0]):\n",
    "#     x = T[i,0]\n",
    "#     y = T[i,1]\n",
    "#     p.circle(x,y,color='blue')\n",
    "    #p.text(x+0.3,y+0.3,flav.index[i])\n",
    "p.scatter('PC1','PC2',color='blue',size=6, source=source)\n",
    "labels = LabelSet(x='PC1', y='PC2', text='names', level='glyph',\n",
    "              x_offset=5, y_offset=5, source=source, render_mode='canvas')    \n",
    "p.add_layout(labels)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# HCA\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "Z = linkage(Xa,'ward')\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "dn = dendrogram(Z,orientation=\"right\", labels=flav.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelos de regressão\n",
    "\n",
    "+ Um modelo de regressão é obtido por meio da resolução do sistema linear\n",
    "\n",
    "$\\mathbf{Xb} = \\mathbf{y}$\n",
    "\n",
    "+ Solução\n",
    "    + $\\mathbf{X^{+}Xb} = \\mathbf{X^{+}y}$\n",
    "    + $\\mathbf{b} = \\mathbf{X^{+}y}$\n",
    "+ Em que $\\mathbf{X^{+}}$ é a inversa generalizada de Moore-Penrose    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelos de regressão\n",
    "\n",
    "+ A resolução do sistema inclui as seguintes soluções:\n",
    "    1. $\\mathbf{X^{+}} = \\mathbf{X^{-1}}$ quando $\\mathbf{X}$ é quadrada e inversível\n",
    "    2. $\\Arrowvert {\\mathbf{y-Xb}} \\Arrowvert^{2} = min$ Solução de quadrados mínimos\n",
    "+ Normalmente essa equação linear é obtida através de um dos seguintes métodos:\n",
    "    + MLR\n",
    "    + PCR\n",
    "    + PLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MLR (do inglês, Muliple Linear Regression)\n",
    "\n",
    "+ Nada mais é que a resolução direta do problema de quadrados mínimos\n",
    "+ A matriz $\\mathbf{X}$ deve ter mais linhas (amostras) que colunas (variáveis)\n",
    "+ As colunas (variáveis) não podem ser correlacionadas, pois assim o sistema não terá uma solução estável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Métodos de projeção\n",
    "\n",
    "+ Devido às limitações impostas pelo método MLR, uma solução é projetar as variáveis da matriz $\\mathbf{X}$ em um espaço de dimensão menor\n",
    "+ Se $\\mathbf{X}$ é uma matriz ($I \\times J$) de posto $P$, ela pode ser decomposta em\n",
    "\n",
    "$\\mathbf{X} = \\mathbf{URW^{t}}$\n",
    "\n",
    "+ $\\mathbf{U}$ é ortonormal de dimensões ($I \\times P$)\n",
    "+ $\\mathbf{W}$ é ortonormal de dimensões ($J \\times P$)\n",
    "+ $\\mathbf{R}$ é não singular de dimensões ($P \\times P$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Métodos de projeção\n",
    "\n",
    "+ Assim temos\n",
    "    + $\\mathbf{R} = \\mathbf{U^{t}XW}$\n",
    "    + $\\mathbf{X^{+}} = \\mathbf{WR^{-1}U^{t}}$\n",
    "+ e, portanto\n",
    "    + $\\mathbf{b} = \\mathbf{WR^{-1}U^{t}y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Métodos de projeção\n",
    "\n",
    "+ Essa formulação é geral e cobre uma infinidade de métodos, dentre os quais destacam-se:\n",
    "    + PCR (A matriz R é diagonal)\n",
    "    + PLS (A matriz R é bidiagonal)\n",
    "+ O método PLS costuma ser mais usado, pois ele projeta as variáveis originais em um espaço de menor dimensão formado pelas variáveis latentes levando em consideração a informação contida na variável dependente   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Carregando novos dados\n",
    "X = pd.read_csv(\"Xdat.txt\",sep='\\t',index_col=0)\n",
    "print(\"Dimensões de X\")\n",
    "print(X.shape)\n",
    "y = pd.read_csv(\"pIC50dat.txt\",sep='\\t')\n",
    "print(\"Dimensões de y\")\n",
    "print(y.shape)\n",
    "\n",
    "# Autoescalando os dados\n",
    "scaler = StandardScaler().fit(X)\n",
    "print(\"Médias de X\")\n",
    "print(scaler.mean_)\n",
    "print(\"Varâncias de X\")\n",
    "print(scaler.var_)\n",
    "# Autoescalando de fato\n",
    "Xa = scaler.transform(X)\n",
    "print(\"Médias de X autoescalado\")\n",
    "print(Xa.mean(axis=0))\n",
    "print(\"Desvios padrão de X autoescalado\")\n",
    "print(Xa.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# MLR\n",
    "\n",
    "from sklearn import linear_model \n",
    "from sklearn.model_selection import cross_val_predict \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mlr = linear_model.LinearRegression()\n",
    "\n",
    "# Fit\n",
    "mlr.fit(Xa, y)\n",
    " \n",
    "# # Calibration\n",
    "y_c = mlr.predict(Xa)\n",
    "y_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_cv = cross_val_predict(mlr, Xa, y, cv=len(Xa))\n",
    "y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "score_c = r2_score(y, y_c)\n",
    "print(score_c)\n",
    "score_cv = r2_score(y, y_cv)\n",
    "print(score_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "X_new = SelectKBest(f_regression, k=6).fit_transform(Xa, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Fit\n",
    "mlr.fit(X_new, y)\n",
    " \n",
    "# # Calibration\n",
    "y_c = mlr.predict(X_new)\n",
    "\n",
    "\n",
    "score_c = r2_score(y, y_c)\n",
    "print(score_c)\n",
    "y_cv = cross_val_predict(mlr, X_new, y, cv=len(y))\n",
    "score_cv = r2_score(y, y_cv)\n",
    "print(score_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# PCR\n",
    "\n",
    "pca = PCA(n_components = 8)\n",
    "pca.fit(Xa)\n",
    "T = pca.fit_transform(Xa)\n",
    "\n",
    "pcr = linear_model.LinearRegression()\n",
    "\n",
    "# Fit\n",
    "pcr.fit(T, y)\n",
    "\n",
    "# Calibration\n",
    "y_c_pcr = pcr.predict(T)\n",
    "\n",
    "# Cross-validation\n",
    "y_cv_pcr = cross_val_predict(pcr, T, y, cv=len(y))\n",
    "\n",
    "# Calculate scores for calibration and cross-validation\n",
    "score_c_pcr = r2_score(y, y_c_pcr)\n",
    "print(score_c_pcr)\n",
    "score_cv_pcr = r2_score(y, y_cv_pcr)\n",
    "print(score_cv_pcr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cv_scores = []\n",
    "c_scores = []\n",
    "mse_c = []\n",
    "mse_cv = []\n",
    "for i in range(8):\n",
    "    Tp = T[:,:i+1]\n",
    "    # Calibration\n",
    "    pcr.fit(Tp,y)\n",
    "    y_c_pcr = pcr.predict(Tp)\n",
    "\n",
    "    # Cross-validation\n",
    "    y_cv_pcr = cross_val_predict(pcr, Tp, y, cv=len(Xa))\n",
    "\n",
    "    # Calculate scores for calibration and cross-validation\n",
    "    c_scores.append(r2_score(y, y_c_pcr))\n",
    "    cv_scores.append(r2_score(y, y_cv_pcr))\n",
    "    mse_c.append(mean_squared_error(y, y_c_pcr))\n",
    "    mse_cv.append(mean_squared_error(y, y_cv_pcr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p = figure(title=\"Erro Quadrático médio\", x_axis_label='Número de componentes', y_axis_label='RMSECV ou RMSEC')\n",
    "    #p.text(x+0.3,y+0.3,flav.index[i])\n",
    "p.line(range(1,len(c_scores)+1),mse_c,legend=\"RMSEC\")\n",
    "p.circle(range(1,len(c_scores)+1),mse_c,legend=\"RMSEC\")\n",
    "p.line(range(1,len(cv_scores)+1),mse_cv,color=\"red\", legend=\"RMSECV\")\n",
    "p.circle(range(1,len(cv_scores)+1),mse_cv,color=\"red\", legend=\"RMSECV\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p = figure(title=\"Erro Validação cruzada\", x_axis_label='Número de componentes', y_axis_label='Q² ou R²')\n",
    "    #p.text(x+0.3,y+0.3,flav.index[i])\n",
    "p.line(range(1,len(c_scores)+1),c_scores,legend=\"R²\")\n",
    "p.circle(range(1,len(c_scores)+1),c_scores,legend=\"R²\")\n",
    "p.line(range(1,len(cv_scores)+1),cv_scores,color=\"red\", legend=\"Q²\")\n",
    "p.circle(range(1,len(cv_scores)+1),cv_scores,color=\"red\", legend=\"Q²\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Tp = T[:,:4]\n",
    "# Calibration\n",
    "pcr.fit(Tp,y)\n",
    "y_c_pcr = pcr.predict(Tp)\n",
    "\n",
    "# Cross-validation\n",
    "y_cv_pcr = cross_val_predict(pcr, Tp, y, cv=len(Xa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(mlr.coef_)\n",
    "print(mlr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(pcr.coef_)\n",
    "print(pcr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# PLS\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "pls2 = PLSRegression(n_components=8)\n",
    "pls2.fit(Xa, y)\n",
    "\n",
    "y_pls = pls2.predict(Xa)\n",
    "print(y_pls)\n",
    "print(pls2.score(Xa,y))\n",
    "\n",
    "y_cv_pls = cross_val_predict(pls2, Xa, y, cv=len(Xa))\n",
    "print(y_cv_pls)\n",
    "print(r2_score(y,y_cv_pls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_cv_pls = cross_val_predict(pls2, Xa, y, cv=len(Xa))\n",
    "print(y_cv_pls)\n",
    "print(r2_score(y,y_cv_pls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cv_scores = []\n",
    "c_scores = []\n",
    "mse_c = []\n",
    "mse_cv = []\n",
    "for i in range(8):\n",
    "    # Calibration\n",
    "    pls2 = PLSRegression(n_components=i+1)\n",
    "    pls2.fit(Xa,y)\n",
    "    y_c_pcr = pls2.predict(Xa)\n",
    "\n",
    "    # Cross-validation\n",
    "    y_cv_pcr = cross_val_predict(pls2, Xa, y, cv=len(Xa))\n",
    "\n",
    "    c_scores.append(r2_score(y, y_c_pcr))\n",
    "    cv_scores.append(r2_score(y, y_cv_pcr))\n",
    "    mse_c.append(mean_squared_error(y, y_c_pcr))\n",
    "    mse_cv.append(mean_squared_error(y, y_cv_pcr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p = figure(title=\"Erro Quadrático médio\", x_axis_label='Número de varáveis latentes', y_axis_label='RMSECV ou RMSEC')\n",
    "    #p.text(x+0.3,y+0.3,flav.index[i])\n",
    "p.line(range(1,len(c_scores)+1),mse_c,legend=\"RMSEC\")\n",
    "p.circle(range(1,len(c_scores)+1),mse_c,legend=\"RMSEC\")\n",
    "p.line(range(1,len(cv_scores)+1),mse_cv,color=\"red\", legend=\"RMSECV\")\n",
    "p.circle(range(1,len(cv_scores)+1),mse_cv,color=\"red\", legend=\"RMSECV\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "source = ColumnDataSource(data=dict(\n",
    "    lv=range(1,len(c_scores)+1),\n",
    "    R2=c_scores,\n",
    "    Q2=cv_scores,\n",
    "))\n",
    "\n",
    "TOOLTIPS = [\n",
    "    (\"LV\", \"@lv\"),\n",
    "    (\"R2\", \"@R2\"),\n",
    "    (\"Q2\", \"@Q2\")\n",
    "]\n",
    "\n",
    "p = figure(title=\"Erro Validação cruzada - PLS\", x_axis_label='Número de variáveis latentes', y_axis_label='Q² ou R²',\n",
    "          tooltips = TOOLTIPS)\n",
    "    #p.text(x+0.3,y+0.3,flav.index[i])\n",
    "p.line(\"lv\",\"R2\",legend=\"R²\", source=source)\n",
    "p.circle(\"lv\",\"R2\",legend=\"R²\", source=source)\n",
    "p.line(\"lv\",\"Q2\",color=\"red\", legend=\"Q²\", source=source)\n",
    "p.circle(\"lv\",\"Q2\",color=\"red\", legend=\"Q²\", source=source)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pls2 = PLSRegression(n_components=2)\n",
    "pls2.fit(Xa, y)\n",
    "\n",
    "y_pls = pls2.predict(Xa)\n",
    "print(pls2.score(Xa,y))\n",
    "\n",
    "y_cv_pls = cross_val_predict(pls2, Xa, y, cv=len(Xa))\n",
    "print(r2_score(y,y_cv_pls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_a = scaler.transform(X_train)\n",
    "pls2 = PLSRegression(n_components=2)\n",
    "pls2.fit(X_train_a, y_train)\n",
    "\n",
    "y_pls = pls2.predict(X_train_a)\n",
    "print(pls2.score(X_train_a,y_train))\n",
    "\n",
    "y_cv_pls = cross_val_predict(pls2, X_train_a, y_train, cv=len(X_train_a))\n",
    "print(r2_score(y_train,y_cv_pls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_test_a = scaler.transform(X_test)\n",
    "y_p = pls2.predict(X_test_a)\n",
    "print(pls2.score(X_test_a,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "Z = linkage(Xa,'ward')\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "dn = dendrogram(Z,orientation=\"right\", labels=[(int(X.index[i]),\"{:.2f}\".format(y[\"pIC50\"][i])) for i in range(len(y))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import LabelSet, Label, ColumnDataSource\n",
    "source = ColumnDataSource(data=dict(x=range(1,1+len(y)),\n",
    "                                    y=y[\"pIC50\"],\n",
    "                                    names=X.index))\n",
    "\n",
    "output_notebook()\n",
    "p = figure(title=\"Atividades\", x_axis_label='Amostras', y_axis_label='pIC50')\n",
    "p.scatter('x','y',color='blue',source=source)\n",
    "labels = LabelSet(x='x', y='y', text='names', level='glyph',\n",
    "              x_offset=5, y_offset=5, source=source, render_mode='canvas')    \n",
    "p.add_layout(labels)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(Xa)\n",
    "T = pca.fit_transform(Xa)\n",
    "source = ColumnDataSource(data=dict(PC1=T[:,0],\n",
    "                                    PC2=T[:,1],\n",
    "                                    names=X.index))\n",
    "\n",
    "output_notebook()\n",
    "p = figure(title=\"PCA\", x_axis_label='PC1', y_axis_label='PC2')\n",
    "# for i in range(np.shape(T)[0]):\n",
    "#     x = T[i,0]\n",
    "#     y = T[i,1]\n",
    "#     p.circle(x,y,color='blue')\n",
    "    #p.text(x+0.3,y+0.3,flav.index[i])\n",
    "p.scatter('PC1','PC2',color='blue',size=6, source=source)\n",
    "labels = LabelSet(x='PC1', y='PC2', text='names', level='glyph',\n",
    "              x_offset=3, y_offset=3, source=source, render_mode='canvas')    \n",
    "p.add_layout(labels)\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
